"""
LLM Transformer Module.
Uses LangChain to integrate with the OpenAI API for generating SpiceDB schemas from Keycloak realm data.
"""

import logging
import os
from langchain.llms import OpenAI
from langchain.chat_models import ChatOpenAI
from langchain.schema import HumanMessage
from k2spicedb.keycloak_parser import KeycloakRealm
from k2spicedb.schema_generator import SchemaGenerator

logger = logging.getLogger(__name__)


class LLMTransformer:
    """
    Converts Keycloak realm data into a SpiceDB schema using a language model.
    Defaults to OpenAI models via LangChain.
    """

    def __init__(self, model_name: str = "o3-mini", temperature: float = 0.0,
                 max_tokens: int = 1000, openai_api_key: str = None, llm=None):
        """
        Initializes the LLM transformer.

        :param model_name: OpenAI model name (e.g., 'o3-mini', 'gpt-4.5').
        :param temperature: Sampling temperature for the LLM (0.0 for deterministic output).
        :param max_tokens: Maximum tokens allowed in the LLM response.
        :param openai_api_key: API key for OpenAI (uses OPENAI_API_KEY env var if None).
        :param llm: Optional custom LLM instance for testing or alternative models.
        """
        self.model_name = model_name

        if llm:
            self.llm = llm
            if hasattr(llm, "model_name"):
                self.model_name = llm.model_name  # Store model name if available
        else:
            # Select appropriate LangChain LLM based on model type
            self.llm = ChatOpenAI(model_name=model_name, temperature=temperature,
                                  max_tokens=max_tokens, openai_api_key=openai_api_key) \
                if model_name.lower().startswith("gpt-") else \
                OpenAI(model_name=model_name, temperature=temperature,
                       max_tokens=max_tokens, openai_api_key=openai_api_key)

    def transform(self, realm: KeycloakRealm) -> str:
        """
        Transforms a KeycloakRealm object into a SpiceDB schema using an LLM.

        :param realm: Parsed Keycloak realm data.
        :return: A generated SpiceDB schema as a string.
        """
        prompt_text = self._generate_prompt(realm)

        try:
            logger.info(f"Generating schema for realm '{realm.name}' using model '{self.model_name}'.")
            logger.debug(f"LLM Prompt:\n{prompt_text}")

            schema_text = self._invoke_llm(prompt_text)
            return schema_text.strip()

        except Exception as e:
            logger.error(f"LLM transformation failed for realm '{realm.name}': {e}")
            logger.info(f"Falling back to deterministic schema generation for realm '{realm.name}'.")
            return SchemaGenerator.generate_schema(realm)

    def _generate_prompt(self, realm: KeycloakRealm) -> str:
        """
        Constructs a detailed prompt for the LLM using Keycloak realm data.

        :param realm: Parsed Keycloak realm data.
        :return: A formatted prompt string.
        """
        details = []

        # Add realm roles
        if realm.realm_roles:
            details.append(f"- Realm roles: {', '.join(realm.realm_roles)}")

        # Add client roles
        for client, roles in realm.client_roles.items():
            details.append(f"- Client '{client}' roles: {', '.join(roles)}")

        # Add composite roles
        for comp, parts in realm.composite_roles.items():
            details.append(f"- Composite role '{comp}' includes: {self._format_composite_roles(parts)}")

        # Add groups (with subgroups if present)
        if realm.groups:
            details.append(f"- Groups: {self._format_groups(realm.groups)}")

        details_text = "\n".join(details) if details else "(No roles or groups)"

        return (
            f"Keycloak realm '{realm.name}' has the following roles and groups:\n"
            f"{details_text}\n\n"
            "Generate a SpiceDB schema definition that represents the above roles and groups.\n"
            "- Define object types for users, groups, and any resources corresponding to clients.\n"
            "- Include relations for group membership and role assignments (using role names as relation or permission names).\n"
            "- If a role is composite or groups have subgroups, represent those relationships (e.g., permissions that combine other roles or a parent-child relation for groups).\n"
            "Output *only* the SpiceDB schema (object definitions) without additional explanation."
        )

    def _invoke_llm(self, prompt_text: str) -> str:
        """
        Sends the prompt to the LLM and retrieves the generated SpiceDB schema.

        :param prompt_text: The formatted prompt to send to the LLM.
        :return: The schema text generated by the LLM.
        """
        if hasattr(self.llm, "predict"):
            return self.llm.predict(prompt_text)  # For LangChain LLMs with a predict method

        if isinstance(self.llm, ChatOpenAI):
            response = self.llm([HumanMessage(content=prompt_text)])
            return response.content if hasattr(response, "content") else str(response)

        return self.llm(prompt_text)  # Fallback to calling the LLM instance directly

    @staticmethod
    def _format_composite_roles(parts: list) -> str:
        """
        Formats composite role data into a readable string.

        :param parts: List of role parts.
        :return: A formatted string representation.
        """
        realm_roles = [p for p in parts if ":" not in p]
        client_roles = {}

        for part in parts:
            if ":" in part:
                client, role = part.split(":", 1)
                client_roles.setdefault(client, []).append(role)

        formatted = []
        if realm_roles:
            formatted.append(f"realm roles [{', '.join(realm_roles)}]")
        for client, roles in client_roles.items():
            formatted.append(f"{client} roles [{', '.join(roles)}]")

        return " and ".join(formatted)

    @staticmethod
    def _format_groups(groups: list) -> str:
        """
        Formats group data, including subgroups.

        :param groups: List of groups.
        :return: A formatted string representation.
        """
        formatted_groups = []
        for group in groups:
            subgroups = [sub.name for sub in group.subgroups] if group.subgroups else []
            formatted_groups.append(f"{group.name} (subgroups: {', '.join(subgroups)})" if subgroups else group.name)

        return ", ".join(formatted_groups)
